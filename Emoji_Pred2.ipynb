{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emoji Pred2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJPLuVz45Yf",
        "colab_type": "code",
        "outputId": "64a1a3f9-2717-4944-fd7f-30e1bea452ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBTh477q1oHw",
        "colab_type": "code",
        "outputId": "4f599750-22a5-45e5-cee5-7a1aac1b96e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import random\n",
        "import twitter\n",
        "import emoji\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import one_hot\n",
        "import keras.callbacks\n",
        "import json\n",
        "\n",
        "import os\n",
        "# import nb_utils\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, Embedding, GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers import Concatenate, Average\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "722D0yB82G5e",
        "colab_type": "code",
        "outputId": "793971b2-37dd-4d1f-ea98-ee8e09183062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip install twitter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twitter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/e2/f602e3f584503f03e0389491b251464f8ecfe2596ac86e6b9068fe7419d3/twitter-1.18.0-py2.py3-none-any.whl (54kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 30kB 6.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61kB 3.7MB/s \n",
            "\u001b[?25hInstalling collected packages: twitter\n",
            "Successfully installed twitter-1.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0hBMuoR2d58",
        "colab_type": "code",
        "outputId": "2649894b-b840-4118-9f40-f6c0c11a32c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 20kB 4.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 3.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42175 sha256=f115e3f3affbd5465f797069c4e04dfc4287763494ea53593ac65ef532b738a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIRhhMME19bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONSUMER_KEY = 'xbMuxcJpRTiVGt2C2EYnA'\n",
        "CONSUMER_SECRET = '2DbQTsvIptkPTdaUcos8DDvQH9fzO0hNjJpUT2uVzQ'\n",
        "ACCESS_TOKEN = '7319442-EDm4CPxL7W4KkZcGWRMJNVHp88W5OH9vgblu898fg'\n",
        "ACCESS_SECRET = '5ZxJSbqXhG7uhgXzTFWf9XhkfsxxinlPRXyDTzbA9w'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHT78EXW2yt7",
        "colab_type": "code",
        "outputId": "26e56701-0391-4c83-ed6e-650e287c9631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "auth=twitter.OAuth(\n",
        "    consumer_key=CONSUMER_KEY,\n",
        "    consumer_secret=CONSUMER_SECRET,\n",
        "    token=ACCESS_TOKEN,\n",
        "    token_secret=ACCESS_SECRET,\n",
        ")\n",
        "\n",
        "status_stream = twitter.TwitterStream(auth=auth).statuses\n",
        "\n",
        "[x['text'] for x in itertools.islice(status_stream.sample(), 0, 5) if x.get('text')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ÿäÿßÿ±ÿ® ÿ®ÿßÿπÿØ ÿ®ŸäŸÜŸä Ÿàÿ®ŸäŸÜ ÿßŸÑŸáŸäÿßÿ∑ ŸÖŸà ŸÜÿßŸÉÿ®ŸÜŸä ÿßŸÑÿß ÿßŸÑŸáŸäÿßÿ∑ ŸÖÿ≥ŸàŸäŸá ÿßŸÜŸä ŸÖÿØÿ±ŸÉŸá ŸÜÿµ ÿßŸÑÿ≥ŸÑÿßŸäÿØÿßÿ™',\n",
              " '@Wf1234123 üíôüíôüíô',\n",
              " '@TcraiScanner Direi che √® proprio una battuta da cinepanettone scadente e scaduto XD',\n",
              " '‰∏°ÊÄù„ÅÑ„Å™„Çì„Å†„Åë„Å©„Åä‰∫í„ÅÑ‰ªò„ÅçÂêà„Åà„Å™„ÅÑ„Å£„Å¶Â†¥Âêà„Å©„ÅÜ„Åô„Çå„Å∞„ÅÑ„ÅÑ„Çì„Åß„Åó„Çá„ÅÜ„ÅãÔºüÔºü',\n",
              " 'RT @JMcintosh91: @KTHopkins Import the 3rd world, become the 3rd world.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiEoRu49230Q",
        "colab_type": "code",
        "outputId": "54fce05a-dff3-46b2-d00d-948d4a701e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "status_stream = twitter.TwitterStream(auth=auth).statuses\n",
        "\n",
        "def english_has_emoji(tweet):\n",
        "    if tweet.get('lang') != 'en':\n",
        "        return False\n",
        "    return any(ch for ch in tweet.get('text', '') if ch in emoji.UNICODE_EMOJI)\n",
        "\n",
        "%time tweets = list(itertools.islice(filter(english_has_emoji, status_stream.sample()), 0, 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.04 s, sys: 93.4 ms, total: 1.13 s\n",
            "Wall time: 56.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXusbOja3Dz7",
        "colab_type": "code",
        "outputId": "6cd233ce-344f-47ea-8db7-b68391f06955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stripped = []\n",
        "for tweet in tweets:\n",
        "    text = tweet['text']\n",
        "    emojis = {ch for ch in text if ch in emoji.UNICODE_EMOJI}\n",
        "    if len(emojis) == 1:\n",
        "        emoiji = emojis.pop()\n",
        "        text = ''.join(ch for ch in text if ch != emoiji)\n",
        "        stripped.append((text, emoiji))\n",
        "len(stripped)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJS2ZqLW3PfZ",
        "colab_type": "text"
      },
      "source": [
        "Using the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhCM6OX_3TMy",
        "colab_type": "code",
        "outputId": "b58921ff-19cc-403b-ef46-62a745935dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "all_tweets = pd.read_csv('/content/drive/My Drive/data/emojis.csv')\n",
        "all_tweets['emoji'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "üòÇ    124823\n",
              "‚ù§     43218\n",
              "üòç     40566\n",
              "üò≠     35714\n",
              "üòä     20076\n",
              "      ...  \n",
              "ü¶à         1\n",
              "üì≥         1\n",
              "üîÄ         1\n",
              "üïú         1\n",
              "üì≠         1\n",
              "Name: emoji, Length: 989, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQGsBe6_44ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glo6ohC83Vof",
        "colab_type": "code",
        "outputId": "0b146e1a-6ed0-46bf-eb68-5c21800d18eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "tweets = all_tweets.groupby('emoji').filter(lambda c:len(c) > 1000)\n",
        "tweets['emoji'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "üòÇ    124823\n",
              "‚ù§     43218\n",
              "üòç     40566\n",
              "üò≠     35714\n",
              "üòä     20076\n",
              "      ...  \n",
              "üò•      1072\n",
              "üôÅ      1066\n",
              "ü§ï      1065\n",
              "üò∞      1013\n",
              "‚òÄ      1013\n",
              "Name: emoji, Length: 121, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Yirmcg336k",
        "colab_type": "code",
        "outputId": "62db1b68-333f-487c-ef76-ac5076e202b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(tweets['text'], key=lambda t:len(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Don't worry, my love, I don't get you wrong Don't get me wrong. We're connected with our hearts, souls, minds, bodies. If any doubt, we ask\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoBUSYAH34st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = list(sorted(set(chain(*tweets['text']))))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "max_sequence_len = max(len(x) for x in tweets['text'])\n",
        "\n",
        "emojis = list(sorted(set(tweets['emoji'])))\n",
        "emoji_to_idx = {em: idx for idx, em in enumerate(emojis)}\n",
        "emojis[:10]\n",
        "\n",
        "train_tweets, test_tweets = train_test_split(tweets, test_size=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "266chW0M3_vV",
        "colab_type": "code",
        "outputId": "db18692a-8629-4cf9-9b3b-a9a3854f92d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "def data_generator(tweets, batch_size):\n",
        "    while True:\n",
        "        if batch_size is None:\n",
        "            batch = tweets\n",
        "            batch_size = batch.shape[0]\n",
        "        else:\n",
        "            batch = tweets.sample(batch_size)\n",
        "        X = np.zeros((batch_size, max_sequence_len, len(chars)))\n",
        "        y = np.zeros((batch_size,))\n",
        "        for row_idx, (_, row) in enumerate(batch.iterrows()):\n",
        "            y[row_idx] = emoji_to_idx[row['emoji']]\n",
        "            for ch_idx, ch in enumerate(row['text']):\n",
        "                X[row_idx, ch_idx, char_to_idx[ch]] = 1\n",
        "        yield X, y\n",
        "\n",
        "next(data_generator(tweets, 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]]),\n",
              " array([  0.,  96.,  65.,  65., 118.,  78.,  96.,  75., 112.,  21.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JijbN2tmyJH",
        "colab_type": "code",
        "outputId": "13b309b2-61a8-481b-be45-4205ba1d86cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "def create_char_cnn_model(num_chars, max_sequence_len, num_labels):\n",
        "    char_input = Input(shape=(max_sequence_len, num_chars), name='char_cnn_input')\n",
        "    \n",
        "    conv_1x = Conv1D(128, 6, activation='relu', padding='valid')(char_input)\n",
        "    max_pool_1x = MaxPooling1D(4)(conv_1x)\n",
        "    conv_2x = Conv1D(256, 6, activation='relu', padding='valid')(max_pool_1x)\n",
        "    max_pool_2x = MaxPooling1D(4)(conv_2x)\n",
        "\n",
        "    flatten = Flatten()(max_pool_2x)\n",
        "    dense = Dense(128, activation='relu')(flatten)\n",
        "    preds = Dense(num_labels, activation='softmax', name='char_cnn_predictions')(dense)\n",
        "\n",
        "    model = Model(char_input, preds)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "char_cnn_model = create_char_cnn_model(len(char_to_idx), max_sequence_len, len(emojis))\n",
        "char_cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "char_cnn_input (InputLayer)  (None, 139, 96)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 134, 128)          73856     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 33, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 28, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               229504    \n",
            "_________________________________________________________________\n",
            "char_cnn_predictions (Dense) (None, 121)               15609     \n",
            "=================================================================\n",
            "Total params: 515,833\n",
            "Trainable params: 515,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnHVvE8bqexf",
        "colab_type": "code",
        "outputId": "476a9625-a837-4bda-8018-d91dbca50d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_tweets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "634695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JAgHMZ2m13D",
        "colab_type": "code",
        "outputId": "ed0a71f0-1111-4070-9914-1784eacfef5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "\n",
        "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                              min_delta=0.03,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "char_cnn_model.fit_generator(\n",
        "    data_generator(train_tweets, batch_size=BATCH_SIZE),\n",
        "    epochs=20,\n",
        "    steps_per_epoch=len(train_tweets)/BATCH_SIZE,\n",
        "    verbose=2,\n",
        "    callbacks=[early]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cc5aecdf779a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWIXMXArqorz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_cnn_model.save(\"/content/drive/My Drive/data/cnn.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f4PfcTF3Fq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model(\"/content/drive/My Drive/data/lstm.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWG1iFasYOu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model(\"/content/drive/My Drive/data/cnn.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bddDy_pg3g7V",
        "colab_type": "code",
        "outputId": "bef36839-2f50-4f67-c9c6-bfa99509445f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "char_cnn_input (InputLayer)  (None, 139, 96)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 134, 128)          73856     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 33, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 28, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               229504    \n",
            "_________________________________________________________________\n",
            "char_cnn_predictions (Dense) (None, 121)               15609     \n",
            "=================================================================\n",
            "Total params: 515,833\n",
            "Trainable params: 515,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU-Zc9lF3sbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model_lstm=load_model(\"/content/drive/My Drive/data/lstm.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVuJaIZzYkfw",
        "colab_type": "code",
        "outputId": "85114e46-1226-4494-a3fa-aba725703528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model_lstm.summary();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_input (InputLayer)      (None, None)              0         \n",
            "_________________________________________________________________\n",
            "lstm_embedding (Embedding)   (None, None, 100)         5000000   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               117248    \n",
            "_________________________________________________________________\n",
            "lstm_predictions (Dense)     (None, 121)               15609     \n",
            "=================================================================\n",
            "Total params: 5,132,857\n",
            "Trainable params: 5,132,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA5I1bt576SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 50000\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(tweets['text'])\n",
        "training_tokens = tokenizer.texts_to_sequences(train_tweets['text'])\n",
        "test_tokens = tokenizer.texts_to_sequences(test_tweets['text'])\n",
        "max_num_tokens = max(len(x) for x in chain(training_tokens, test_tokens))\n",
        "training_tokens = pad_sequences(training_tokens, maxlen=max_num_tokens)\n",
        "test_tokens = pad_sequences(test_tokens, maxlen=max_num_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdC6Skka3wsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_char_vectors, _ = next(data_generator(test_tweets, None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_atjligj-Cx7",
        "colab_type": "code",
        "outputId": "f31e76f0-dd1e-46e3-e3b9-d271673fc872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "def load_weights(tokenizer):\n",
        "    model = Word2Vec.load('/content/drive/My Drive/data/twitter_stream_w2v.model')\n",
        "    w2v = np.zeros((tokenizer.num_words, w2v_model.syn0.shape[1]))\n",
        "    for k, v in tokenizer.word_index.items():\n",
        "        if v >= tokenizer.num_words:\n",
        "            continue\n",
        "        if k in w2v_model:\n",
        "            w2v[v] = w2v_model[k]\n",
        "    return w2v\n",
        "model = Word2Vec.load('/content/drive/My Drive/data/twitter_stream_w2v.model')\n",
        "w2v = np.zeros((tokenizer.num_words, model.wv.syn0.shape[1]))\n",
        "found = 0\n",
        "for k, v in tokenizer.word_index.items():\n",
        "    if v >= tokenizer.num_words:\n",
        "        continue\n",
        "    if k in model:\n",
        "        w2v[v] = model[k]\n",
        "        found += 1\n",
        "found, tokenizer.num_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17267, 50000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vKo7sfG7eCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = {\n",
        "    label: [emojis[np.argmax(x)] for x in pred]\n",
        "    for label, pred in (\n",
        "        ('lstm', model_lstm.predict(test_tokens[:1000])),\n",
        "        ('char_cnn', model.predict(test_char_vectors[:1000])),\n",
        "        \n",
        "    )\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUKZQKfu-V0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgTSmJBm7oKY",
        "colab_type": "code",
        "outputId": "3325c41e-9f3a-42db-84dd-2fb6920f6a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "pd.options.display.max_colwidth = 128\n",
        "test_df = test_tweets[:1000].reset_index()\n",
        "eval_df = pd.DataFrame({\n",
        "    'content': test_df['text'],\n",
        "    'true': test_df['emoji'],\n",
        "    **predictions\n",
        "})\n",
        "eval_df[['content', 'true', 'char_cnn', 'lstm']].head(25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>true</th>\n",
              "      <th>char_cnn</th>\n",
              "      <th>lstm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i love being sick on game days</td>\n",
              "      <td>üò©</td>\n",
              "      <td>üò©</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@_white_girl_xo:   Death becomes of those who make lovely things like this. @nt_losechesters</td>\n",
              "      <td>üò≠</td>\n",
              "      <td>üò≠</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@malikofori: This is still the funniest story on twitter.</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank you so much PICE AggregatesRailsACI. Lavern Civil</td>\n",
              "      <td>üòä</td>\n",
              "      <td>‚ù§</td>\n",
              "      <td>üòä</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Rafurl: Laughs infinixically</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@acidhunk: goodmorning today feels like a perfect day to have a mental breakdown</td>\n",
              "      <td>üòä</td>\n",
              "      <td>üòä</td>\n",
              "      <td>üòä</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@camerondallas: RT this &amp; Tweet \" I vote @camerondallas for Entertainer of The Year #Streamys\" for a follow</td>\n",
              "      <td>üòä</td>\n",
              "      <td>üòä</td>\n",
              "      <td>üòä</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@valivy1: Bye Elnella ... We r behind u all way!!!</td>\n",
              "      <td>‚ù§</td>\n",
              "      <td>‚ù§</td>\n",
              "      <td>‚ù§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Omg it's lit @FrankArensMusic</td>\n",
              "      <td>üòç</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üî•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>You dont have any right to call me fat, Coz in the first place, I didn't even call you ugly!!! #ayawkogbiklaLage! #malditako!</td>\n",
              "      <td>üòà</td>\n",
              "      <td>üòà</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>@badgyaltam: follow @t.bluglitter on Instagram guys</td>\n",
              "      <td>üíñ</td>\n",
              "      <td>üì∑</td>\n",
              "      <td>‚ù§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>@MariaShawntrice: Once you get attached to someone everything they do affects you.</td>\n",
              "      <td>üòî</td>\n",
              "      <td>üòî</td>\n",
              "      <td>üòî</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>@TheBlackHardy: So you and me, @Tony_Starkx</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üíØ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>@FunnyBrawls: LMAO well, that escalated quickly</td>\n",
              "      <td>üíÄ</td>\n",
              "      <td>üíÄ</td>\n",
              "      <td>üíÄ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>@1YOWDA @mymixtapez @1YOWDA is hilarious fam smfh</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>did I really just see that girlfriends on sale on my TL? y'all wild man</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>I hope y'all have a blessed positive day!</td>\n",
              "      <td>‚ù§</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>‚ù§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>@PapiFranquito: Deadass spit up my food watching this</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>@urbandoll: RT to win: UD VAULT. must be following me, @artfulIy &amp; @SadScreenshots_ good luck</td>\n",
              "      <td>üíõ</td>\n",
              "      <td>üíõ</td>\n",
              "      <td>üíõ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>@charleylousmith: So crazy how your gut instinct generally always turns out to be right</td>\n",
              "      <td>üò≥</td>\n",
              "      <td>üò≥</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>I like this 'Cleopatra' girl Whuuuu #TheQueenMzansi</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>@ganpppp: 160923 EST #Mark #BamBam what are you talking about</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>üòÇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>@LisaSurihani: honoured to wear this beautiful piece #KistinaTop #JovianMandagieforZalora #ZALORAMY</td>\n",
              "      <td>‚ù§</td>\n",
              "      <td>üòç</td>\n",
              "      <td>‚ù§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>@5SOSFangirlLife: Hey,I just write something for Ash and I really hope he can see it can you help me and rt #HappyThoughtsFo...</td>\n",
              "      <td>üòò</td>\n",
              "      <td>üòò</td>\n",
              "      <td>üòò</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>how ten minutes talking to him can completely reverse my mood</td>\n",
              "      <td>‚ò∫</td>\n",
              "      <td>üôÉ</td>\n",
              "      <td>üò©</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                            content  ... lstm\n",
              "0                                                                                                    i love being sick on game days  ...    üòÇ\n",
              "1                                      @_white_girl_xo:   Death becomes of those who make lovely things like this. @nt_losechesters  ...    üòÇ\n",
              "2                                                                         @malikofori: This is still the funniest story on twitter.  ...    üòÇ\n",
              "3                                                                           Thank you so much PICE AggregatesRailsACI. Lavern Civil  ...    üòä\n",
              "4                                                                                                     @Rafurl: Laughs infinixically  ...    üòÇ\n",
              "5                                                  @acidhunk: goodmorning today feels like a perfect day to have a mental breakdown  ...    üòä\n",
              "6                       @camerondallas: RT this & Tweet \" I vote @camerondallas for Entertainer of The Year #Streamys\" for a follow  ...    üòä\n",
              "7                                                                                @valivy1: Bye Elnella ... We r behind u all way!!!  ...    ‚ù§\n",
              "8                                                                                                     Omg it's lit @FrankArensMusic  ...    üî•\n",
              "9     You dont have any right to call me fat, Coz in the first place, I didn't even call you ugly!!! #ayawkogbiklaLage! #malditako!  ...    üòÇ\n",
              "10                                                                              @badgyaltam: follow @t.bluglitter on Instagram guys  ...    ‚ù§\n",
              "11                                               @MariaShawntrice: Once you get attached to someone everything they do affects you.  ...    üòî\n",
              "12                                                                                      @TheBlackHardy: So you and me, @Tony_Starkx  ...    üòÇ\n",
              "13                                                                                  @FunnyBrawls: LMAO well, that escalated quickly  ...    üíÄ\n",
              "14                                                                                @1YOWDA @mymixtapez @1YOWDA is hilarious fam smfh  ...    üòÇ\n",
              "15                                                          did I really just see that girlfriends on sale on my TL? y'all wild man  ...    üòÇ\n",
              "16                                                                                        I hope y'all have a blessed positive day!  ...    ‚ù§\n",
              "17                                                                            @PapiFranquito: Deadass spit up my food watching this  ...    üòÇ\n",
              "18                                    @urbandoll: RT to win: UD VAULT. must be following me, @artfulIy & @SadScreenshots_ good luck  ...    üíõ\n",
              "19                                          @charleylousmith: So crazy how your gut instinct generally always turns out to be right  ...    üòÇ\n",
              "20                                                                              I like this 'Cleopatra' girl Whuuuu #TheQueenMzansi  ...    üòÇ\n",
              "21                                                                    @ganpppp: 160923 EST #Mark #BamBam what are you talking about  ...    üòÇ\n",
              "22                              @LisaSurihani: honoured to wear this beautiful piece #KistinaTop #JovianMandagieforZalora #ZALORAMY  ...    ‚ù§\n",
              "23  @5SOSFangirlLife: Hey,I just write something for Ash and I really hope he can see it can you help me and rt #HappyThoughtsFo...  ...    üòò\n",
              "24                                                                    how ten minutes talking to him can completely reverse my mood  ...    üò©\n",
              "\n",
              "[25 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICnbRjfr_VvT",
        "colab_type": "code",
        "outputId": "3b4d02f7-f894-462b-8003-dcf5fa9bd169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "\n",
        "emotion_df['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN408w9l_Tfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "\n",
        "emotion_csv = get_file('text_emotion.csv', \n",
        "                       'https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv')\n",
        "emotion_df = pd.read_csv(emotion_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5UsthCB_ZNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "VOCAB_SIZE = 50000\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(emotion_df['content'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu18nBl5_ohy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import gensim\n",
        "\n",
        "CACHE_DIR = os.path.expanduser('~/.cache/dl-cookbook')\n",
        "\n",
        "def download(url):\n",
        "    filename = os.path.join(CACHE_DIR, re.sub('[^a-zA-Z0-9.]+', '_', url))\n",
        "    if os.path.exists(filename):\n",
        "        return filename\n",
        "    else:\n",
        "        os.system('mkdir -p \"%s\"' % CACHE_DIR)\n",
        "        assert os.system('wget -O \"%s\" \"%s\"' % (filename, url)) == 0\n",
        "        return filename\n",
        "    \n",
        "    \n",
        "def load_w2v(tokenizer=None):\n",
        "    word2vec_gz = download('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz')\n",
        "    word2vec_vectors = word2vec_gz.replace('.gz', '')\n",
        "    if not os.path.exists(word2vec_vectors):\n",
        "        assert os.system('gunzip -d --keep \"%s\"' % word2vec_gz) == 0\n",
        "        \n",
        "    w2v_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_vectors, binary=True)\n",
        "    \n",
        "    total_count = sum(tokenizer.word_counts.values())\n",
        "    idf_dict = { k: np.log(total_count/v) for (k,v) in tokenizer.word_counts.items() }\n",
        "    \n",
        "    w2v = np.zeros((tokenizer.num_words, w2v_model.syn0.shape[1]))\n",
        "    idf = np.zeros((tokenizer.num_words, 1))\n",
        "\n",
        "    for k, v in tokenizer.word_index.items():\n",
        "        if v >= tokenizer.num_words:\n",
        "            continue\n",
        "\n",
        "        if k in w2v_model:\n",
        "            w2v[v] = w2v_model[k]\n",
        "            idf[v] = idf_dict[k]\n",
        "\n",
        "    del w2v_model\n",
        "    return w2v, idf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FNLQOux_jBD",
        "colab_type": "code",
        "outputId": "d6211f2b-67c2-453e-86d5-19d23f87cc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "w2v, idf = load_w2v(tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBs0aIjDDSTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z7_Q9IOoDSpV",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "chars = list(sorted(set(chain(*emotion_df['content']))))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "max_sequence_len = max(len(x) for x in emotion_df['content'])\n",
        "\n",
        "char_vectors = []\n",
        "for txt in emotion_df['content']:\n",
        "    vec = np.zeros((max_sequence_len, len(char_to_idx)))\n",
        "    vec[np.arange(len(txt)), [char_to_idx[ch] for ch in txt]] = 1\n",
        "    char_vectors.append(vec)\n",
        "char_vectors = np.asarray(char_vectors)\n",
        "char_vectors = pad_sequences(char_vectors)\n",
        "labels = label_encoder.transform(emotion_df['sentiment'])\n",
        "\n",
        "\n",
        "def split(lst):\n",
        "    training_count = int(0.9 * len(char_vectors))\n",
        "    return lst[:training_count], lst[training_count:]\n",
        "\n",
        "training_char_vectors, test_char_vectors = split(char_vectors)\n",
        "training_labels, test_labels = split(labels)\n",
        "\n",
        "char_vectors.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts-sD2Js_mgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = tokenizer.texts_to_sequences(emotion_df['content'])\n",
        "tokens = pad_sequences(tokens)\n",
        "\n",
        "\n",
        "\n",
        "training_tokens, training_labels = tokens[:training_count], labels[:training_count]\n",
        "test_tokens, test_labels = tokens[training_count:], labels[training_count:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMG1VAGCA1kk",
        "colab_type": "code",
        "outputId": "4957774b-c097-4df1-85bb-01997090cb2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "from keras import layers, models\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def make_embedding(name, vocab_size, embedding_size, weights=None, mask_zero=True):\n",
        "    if weights is not None:\n",
        "        return layers.Embedding(mask_zero=mask_zero, input_dim=vocab_size, \n",
        "                                output_dim=weights.shape[1], \n",
        "                                weights=[weights], trainable=False, \n",
        "                                name='%s/embedding' % name)\n",
        "    else:\n",
        "        return layers.Embedding(mask_zero=mask_zero, input_dim=vocab_size, \n",
        "                                output_dim=embedding_size,\n",
        "                                name='%s/embedding' % name)\n",
        "\n",
        "def create_unigram_model(vocab_size, embedding_size=None, embedding_weights=None, idf_weights=None):\n",
        "    assert not (embedding_size is None and embedding_weights is None)\n",
        "    message = layers.Input(shape=(None,), dtype='int32', name='message')\n",
        "    \n",
        "    embedding = make_embedding('message_vec', vocab_size, embedding_size, embedding_weights)\n",
        "    idf = make_embedding('message_idf', vocab_size, embedding_size, idf_weights)\n",
        "\n",
        "    mask = layers.Masking(mask_value=0)\n",
        "    def _combine_and_sum(args):\n",
        "        embedding, idf = args\n",
        "        return K.sum(embedding * K.abs(idf), axis=1)\n",
        "\n",
        "    sum_layer = layers.Lambda(_combine_and_sum, name='combine_and_sum')\n",
        "    sum_msg = sum_layer([mask(embedding(message)), idf(message)])\n",
        "    fc1 = layers.Dense(units=128, activation='relu')(sum_msg)\n",
        "    categories = layers.Dense(units=len(label_encoder.classes_), activation='softmax')(fc1)\n",
        "    \n",
        "    model = models.Model(\n",
        "        inputs=[message],\n",
        "        outputs=categories,\n",
        "    )\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "unigram_model = create_unigram_model(vocab_size=VOCAB_SIZE,\n",
        "                                     embedding_weights=w2v,\n",
        "                                     idf_weights=idf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cfcd4fde64c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m unigram_model = create_unigram_model(vocab_size=VOCAB_SIZE,\n\u001b[1;32m     42\u001b[0m                                      \u001b[0membedding_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                      idf_weights=idf)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-cfcd4fde64c3>\u001b[0m in \u001b[0;36mcreate_unigram_model\u001b[0;34m(vocab_size, embedding_size, embedding_weights, idf_weights)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msum_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     model = models.Model(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'label_encoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSpJBU0lA-7z",
        "colab_type": "code",
        "outputId": "4eca0c94-4f96-4e7e-ea93-f30adfe0f60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from itertools import chain\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "chars = list(sorted(set(chain(*emotion_df['content']))))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "max_sequence_len = max(len(x) for x in emotion_df['content'])\n",
        "\n",
        "char_vectors = []\n",
        "for txt in emotion_df['content']:\n",
        "    vec = np.zeros((max_sequence_len, len(char_to_idx)))\n",
        "    vec[np.arange(len(txt)), [char_to_idx[ch] for ch in txt]] = 1\n",
        "    char_vectors.append(vec)\n",
        "char_vectors = np.asarray(char_vectors)\n",
        "char_vectors = pad_sequences(char_vectors)\n",
        "labels = label_encoder.transform(emotion_df['sentiment'])\n",
        "\n",
        "\n",
        "def split(lst):\n",
        "    training_count = int(0.9 * len(char_vectors))\n",
        "    return lst[:training_count], lst[training_count:]\n",
        "\n",
        "training_char_vectors, test_char_vectors = split(char_vectors)\n",
        "training_labels, test_labels = split(labels)\n",
        "\n",
        "char_vectors.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 167, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTkcwkfJBpyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "VOCAB_SIZE = 50000\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(max_features=VOCAB_SIZE)\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "X = tfidf_vec.fit_transform(emotion_df['content'])\n",
        "y = label_encoder.fit_transform(emotion_df['sentiment'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98C1RyAuCAk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}